{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "fashion|образом|shuffle|перестановка|estimator|оценка\n",
    "||||dump batch|массив пакетов\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "arbitrarily|произвольно|split|отобрали|whatever|какой-бы\n",
    "deviation|отклонение|interchange|обмениваться|fairly|довольно\n",
    "considered|считается|rare|редко|pronounce|произношение\n",
    "vocabulary|словарь|mouthful|полный рот|batches|партии\n",
    "entirely|полностью|horrible |ужас||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "influential|влиятельный|opinion|мнение|unfortunately|к сожалению\n",
    "guess|предположить|unfortunately|к сожалению|fair|справедливый\n",
    "exactly|точно|sure|уверен|gonna|собираюсь\n",
    "hit|удар|impact|удар|alone|в одиночестве\n",
    "necessarily|необязательно|assume|предположить|stuff|материал\n",
    "straight|сразу|explanations|объяснения|fair|справедливы\n",
    "fresh|свежие|bias|предвзятости|it hasn't simply|это не просто\n",
    "essentially|по существу|popping|вынимаю|trick|трюк\n",
    "opposed|противоположна|yep|ага||\n",
    "|||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "mean|означает|essence|сущность|kindly|любезно\n",
    "moreover|еще|ultimate|окончательный|offer|предложение\n",
    "although|хотя|assuming|при условии|nessessary|необходимые\n",
    "acctually|фактически|keep|продолжать|treat|расценивать\n",
    "otherwise|хотя|average|средний|somewere|где-то\n",
    "somewere|где-то|similarly|аналогично|bring|приводить\n",
    "feed|скормить|noticed|отметить||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "huge|огромный|amnesty|амнистия|throughout|на протяжении\n",
    "dataset|набор данных|exploration|исследования|accuracy|точность\n",
    "overfitting|переобучение|somehow|как-то|ahead|впереди\n",
    "met|встречал|covered|покрывает|decision|решение\n",
    "embedded|встроенные|wasting|потеря|estimate|оценивает\n",
    "takes|принимает|evaluate|оценивается|performance|производительность\n",
    "assuming|предполагаю|Cleanup|уборка|Eager|стремительное\n",
    "No more|нет больше|consistent|последовательный|gonna|собираюсь\n",
    "recently|недавно|advantage|преимущества|mean|означает\n",
    "leave|оставить|redundant|избыточный|particular|конкретная\n",
    "|||||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "|||||\n",
    "origin|происхождения|rather|скорее|frequently|часто\n",
    "treat|трактуются|amnesty|амнистия|amidst|посреди\n",
    "fashion|мода|immunised|иммунизированной||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "So far|пока|breadth|ширина|away|на расстоянии\n",
    "reached|достигнуты|aware|знать|Similar|Аналогичный\n",
    "Whereas|когда|Notice how|обратите внимани|unlike|в отличие\n",
    "Instead|Вместо|approach|подходить|amazing|удивительный\n",
    "probably|наверное|mastering|освоение|benefit|выгода\n",
    "Interacting|взаимодейсвие|secure|безопасность|appreciated|оценили\n",
    "involved|участвуют|Parsing|разбор|predictions|прогнозы\n",
    "imply|обычно|scopes|цели|responsibilities|обязанности\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "DataFrame|таблица|ransom|выкупная|Eventually|в конце концов\n",
    "Snooping|искать|suspects|подозреваемые|narrow|сузить\n",
    "accepts|получает|witness|свидетели||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "mood|настроение|swings|качели|Hazards|опасности\n",
    "habit|привычка|sneaky|подлых|approach|подход\n",
    "issues|проблемы|tense|натянуто|perform|выполнения\n",
    "exact|точное|indices|индексы|declarative|описательное\n",
    "offers|предлагает|handle|обрабатывает|write out|описать\n",
    "instead|вместо|mentioned|упомянутого|avoid|избежать\n",
    "Consider|рассмотрим|browsing|просматриваем|to track|отследить\n",
    "made up|сделан|behaviour|поведение|side|побочный\n",
    "consequences|последствия|confidence|уверенность|traps|ловушки\n",
    "distinct|особый|exciting|захватывающе|rest|оставшиеся\n",
    "solve|решили|necessary|необходимо|accomplish|выполнить\n",
    "vice versa|наоборот|omit|пропустить|arbitrary|произвольный\n",
    "so far|уже|bolster|укрепить|hesitate|стесняться\n",
    "approach|подход|navy|флот|Survey|обследование\n",
    "Definitely|определенно|ensures|гарантирует|involve|включает\n",
    "improving|улучшать||||\n",
    "|||||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "frequent|частый|malicious|вредный|vulnerable|уязвимый\n",
    "stealing|кражи|sensitive|конфиденциальный|dangerous|опасными\n",
    "mitigating|смягчать|adopting|применение|heuristic|поисковый\n",
    "wings|крылья|follower|последователь||\n",
    "|||||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_|_|_|_|_|_\n",
    "--|--|--|--|--|--\n",
    "|grateful caterwauling tuna|благодарный гусеничный тунец|||\n",
    "|jelly future ferret|желе будущее хорька|||\n",
    "|fabulous-stirring-passbook|сказочная-перемешивающая-сберкнижка|||\n",
    "|creative-everlasting-side|творческая вечная сторона|||\n",
    "|lofty-clammy-drink|высокий липкий напиток|||\n",
    "|||||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Introduction-to-the-JSON-APIs-and-AJAX-Challenges](./d10mongodb.ipynb#1.2.1.-Introduction-to-the-JSON-APIs-and-AJAX-Challenges)  \n",
    "[Technical-Documentation-Page](./d60siteprj.ipynb#4.-Build-a-Technical-Documentation-Page)  \n",
    "[]()  \n",
    "[]()  \n",
    "[]()  \n",
    "[]()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build a Tribute Page\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "f  = () => {\n",
    "var s = \"\";\n",
    "var link = document.location[\"href\"];\n",
    "var title = document.getElementsByTagName(\"title\")[0].text;\n",
    "s = `[${title}](${link})   `;\n",
    "console.log(s);\n",
    "}\n",
    "f()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### to json array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RecipePane', '#delete-', '#edit-', '.recipe-body', '  ul.ingredient list', '    ingredients', '  ol.directions list', '    directions', '--\\t', 'Dialog', '{this.props.dialogType}', 'Add a Recipe', 'Edit Recipe', 'Recipe', 'textarea#{this.props.nameID}', 'Ingredients', 'textarea#{this.props.ingredientsID}', 'Directions', 'textarea#{this.props.directionsID}', 'button.corner-close', 'button#{this.props.submitID}', 'button#{this.props.closeID}', '--', 'IndexView', '#index-view', '.index-view-item']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = '''\n",
    "\n",
    "\n",
    "RecipePane\n",
    "#delete-\n",
    "#edit-\n",
    ".recipe-body\n",
    "  ul.ingredient list\n",
    "    ingredients\n",
    "  ol.directions list\n",
    "    directions\n",
    "--\t\n",
    "Dialog\n",
    "{this.props.dialogType}\n",
    "Add a Recipe\n",
    "Edit Recipe\n",
    "Recipe\n",
    "textarea#{this.props.nameID}\n",
    "Ingredients\n",
    "textarea#{this.props.ingredientsID}\n",
    "Directions\n",
    "textarea#{this.props.directionsID}\n",
    "button.corner-close\n",
    "button#{this.props.submitID}\n",
    "button#{this.props.closeID}\n",
    "--\n",
    "IndexView\n",
    "#index-view\n",
    ".index-view-item\n",
    "\n",
    "'''\n",
    "l = s.split('\\n')\n",
    "l2 = []\n",
    "for i in l:\n",
    "    if i.strip() != \"\":\n",
    "        l2.append(i)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 00:03\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s1 = '00:03'\n",
    "i = re.sub(r'\\d\\d:\\d\\d', \"\", s1) \n",
    "print(len(i),s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doesn't Eugene into global variables and\n",
      "the tensorflow 2.0 has also removed this\n",
      "essence the earlier in tensorflow\n",
      "we had to use the system dot run and now\n",
      "the tensorflow 2.0 is kindly kind of\n",
      "bringing it like a function call and\n",
      "moreover now the tensor flew to point X\n",
      "R to find zero brings the clearance at\n",
      "the core of the tensor flow which\n",
      "ultimately increases the you know\n",
      "improves the accuracy that that actually\n",
      "can increase the accuracy but that is\n",
      "not 100% sure that that increases the\n",
      "accuracy but moreover it reduced the\n",
      "training and the testing time since the\n",
      "Kira's has been integrated with the core\n",
      "of the tensor flow and in that case the\n",
      "its execution will be the faster\n",
      "actually and it also takes a less space\n",
      "and moreover it is the consistent and if\n",
      "you want to know more about the tensor\n",
      "flow 2.0 what I it is offering you can\n",
      "go ahead and visit this link it has\n",
      "Google IO link there and at the Google\n",
      "i/o you can you know to see this the\n",
      "complete the getting started with the\n",
      "tensor flow 2.0 at the Google i/o so the\n",
      "air google has released this tensor flow\n",
      "2.0 and they have covered almost\n",
      "everything what is the new in the tensor\n",
      "flow 2.0\n",
      "there are so many things to the new into\n",
      "the tensorflow 2.0 although this is the\n",
      "new video series and we will be learning\n",
      "a lot about the tensorflow\n",
      "2.0 throughout this video series now the\n",
      "let's go ahead the very quickly and I'm\n",
      "assuming that you have already installed\n",
      "the an akuna at the necessary library\n",
      "only you need to install the tensorflow\n",
      "and if you do remember the previously\n",
      "you need to install the chaos and the\n",
      "tensorflow separately but here you only\n",
      "need to install that cancer flow you\n",
      "actually don't need to install the\n",
      "Kiera's so you can call the pip install\n",
      "tensorflow equal to equal to the 2.0 RC\n",
      "and you can go ahead to this github link\n",
      "where you can get the tensorflow the\n",
      "released okay so here we have a\n",
      "tensorflow 2.0 and you can visit that I\n",
      "think with this yes so here we have a\n",
      "you know the latest tensorflow the 2.0\n",
      "this this one is the not the latest one\n",
      "although with the website if you go and\n",
      "visit on the website there you will get\n",
      "a latest one the tensorflow 2.0 the\n",
      "release candidate is available and you\n",
      "just go ahead there you will get the\n",
      "link here to install this so you can\n",
      "keep monitoring this mission this link\n",
      "to get the updated version by the time\n",
      "I'm making this video this is the latest\n",
      "version now let's go ahead and open\n",
      "anaconda into administrator mode\n",
      "remember you need to open it into the\n",
      "administrator mode otherwise it would\n",
      "not be able to install the tensorflow\n",
      "2.0 in your computer because of the\n",
      "right permission now let's go ahead and\n",
      "copy this which I can just copy it and\n",
      "in the anaconda right the pressing the\n",
      "right click it will paste here the PIP\n",
      "installed tensorflow equal to equal to\n",
      "two point zero point zero RC 0 that if\n",
      "the release candidate 0 let's go ahead\n",
      "and hit the enter although I have\n",
      "already installed the tensorflow 2.0\n",
      "that's why it is saying that the\n",
      "all the requirement has been already\n",
      "satisfied but if you do not have the\n",
      "tensorflow 2.0 installed in your\n",
      "computer you can install and the\n",
      "moreover if you get the any error then\n",
      "you can first uninstall the previous\n",
      "tensorflow for that you can right there\n",
      "pip uninstalled tensorflow so it will\n",
      "uninstall your previous versions and\n",
      "then you can install a new version of a\n",
      "tensorflow\n",
      "okay perfect now let's go ahead and see\n",
      "if you have a GPU in your computer then\n",
      "you can also install a GPU version of a\n",
      "tensorflow\n",
      "right so these are the two ways where\n",
      "you can install a tensorflow in your\n",
      "computer now you can pause the video and\n",
      "pause this video and that you can\n",
      "continue this video after installing the\n",
      "tensorflow\n",
      "2.0 alright now let's go ahead import\n",
      "the fashion mms data set so in this\n",
      "lesson we will be working on the finest\n",
      "fashion m-miss data set the fashion m\n",
      "needs to data set the link is available\n",
      "here and this working we working file is\n",
      "available in the video description from\n",
      "where you can download and if you visit\n",
      "this fashion m niche then you see here\n",
      "on the github the link is available and\n",
      "on the github it says that this is\n",
      "Jolanda article images it has 60\n",
      "thousands examples and every sample have\n",
      "20 28 cross 28 grayscale images and so\n",
      "these are the images and it has a 10\n",
      "actually it has two total the ten\n",
      "classes and that's mean there are 10\n",
      "type of the the fashion images are of\n",
      "level in this fashion amidst dataset\n",
      "okay so these are the images which are\n",
      "available and and and and this sixty\n",
      "thousand images which we will be using\n",
      "to train and ten thousand images to\n",
      "we'll be using to evaluate and it has\n",
      "total the ten categories of these images\n",
      "ok now let's go ahead\n",
      "and first import our learner now first\n",
      "let's go ahead and import the tensorflow\n",
      "and then I'll show you how you can\n",
      "download this the amnesty data set\n",
      "directly into your Jupiters notebook\n",
      "instead of downloading it from a geek\n",
      "health ok / pets to import the\n",
      "tensorflow you need to write their the\n",
      "import and then the tensorflow\n",
      "there we have a tensor flow as usual\n",
      "tensor flow as DF and then we need to\n",
      "improve the care as from the tensor flow\n",
      "so here we have a from tensor flow\n",
      "import the Kira's okay so now we have\n",
      "got sorry we have got the tensor flow\n",
      "and in the chaos sorry yeah now we have\n",
      "imported the Kira's from a tensor flow\n",
      "now let's go ahead and import other\n",
      "necessary libraries like numpy pandas\n",
      "and the matplotlib so those things we\n",
      "can say that a helper liability but\n",
      "before that let's go ahead and check a\n",
      "tensor flow version which you can just\n",
      "check from a print T F dot version so\n",
      "this says that we have Overson 2.0\n",
      "installed in my computer now let's go\n",
      "ahead and import helper libraries like\n",
      "an umpire Pentagon the matplotlib so in\n",
      "the previous videos we have been\n",
      "importing these libraries very\n",
      "frequently numpy as in P and import\n",
      "pandas HPD and then import might float\n",
      "lib dot type lot as PLT so here we have\n",
      "matplotlib i the pandas and the numpy\n",
      "imported in our computer so these things\n",
      "we can treat as a helper libraries now\n",
      "let's go ahead and load the amnesty\n",
      "person dataset so for that i can write\n",
      "here the amidst is equal to\n",
      "the Kyra's dot datasets and then I can\n",
      "write there the fashion I'm honest so\n",
      "with this we will get a pass anemones\n",
      "dataset although I have already\n",
      "downloaded it my computer otherwise it\n",
      "might take a little time in your\n",
      "computer to download this data set from\n",
      "a internet that might take a few seconds\n",
      "if you have a fast internet now let's go\n",
      "ahead and check the type of the\n",
      "immunised this says that with this\n",
      "immunised actually it has downloaded the\n",
      "data sets in a tensor flow module\n",
      "wrapper now what we need to do now we\n",
      "need to actually load the data now we\n",
      "need to load this data into into a real\n",
      "real variables in this jupiter notebook\n",
      "and to do that it actually returns a\n",
      "tuple ok the two tuples wonderful for\n",
      "the training and another tougher for the\n",
      "testing so for this what we can do here\n",
      "the m in each dot a load data set as\n",
      "usual we have been doing into a scalar\n",
      "now in this topple we need to first down\n",
      "get the data into our our the training\n",
      "dataset that is the extreme and then\n",
      "finally Whiterun and the next couple in\n",
      "the next it returns the testing data\n",
      "sets it has X underscore test and then Y\n",
      "underscore test so it has a 60,000 rows\n",
      "for a training which we can verify that\n",
      "with X train dot safe now there you see\n",
      "here there are 60,000 images are\n",
      "available there and each images have 28\n",
      "cross 28 some since there are 60,000\n",
      "images that's mean it should have a\n",
      "60,000 y train as well so let's go ahead\n",
      "and check the safe of Y trend which says\n",
      "that it has a 60,000 okay now let's go\n",
      "ahead and print the X train and see what\n",
      "happens\n",
      "once we print the extreme we see the\n",
      "values the most of the values we are\n",
      "printing here 0 that is because you note\n",
      "at the ages since this is the grayscale\n",
      "so at the edges the most of the images\n",
      "values are 0\n",
      "otherwise the maximum value inside this\n",
      "the area which we can find that within P\n",
      "dot max okay so that's it the 255 so the\n",
      "minimum we have already seen in there\n",
      "and that that is the zero but here are\n",
      "the max is 255 and if we see the average\n",
      "that's mean the N P dot mean the X train\n",
      "so it says that something so moreover\n",
      "now we can we can say that the values is\n",
      "somewhere in between 0 and the 255 okay\n",
      "inside this data set which we later we\n",
      "need to bring down in between 0 and 1 to\n",
      "train with the tensor flow tensor flow\n",
      "model okay our deep learning model and\n",
      "these 60,000 images are classified into\n",
      "ten labels and those labels are encoded\n",
      "into a numerical values and those\n",
      "numerical values we can see with the Y\n",
      "under escort rain and those numerical\n",
      "values are in between 0 & 1 sorry 0 1 9\n",
      "okay so it starts from the 0 until the 9\n",
      "so those are the 10 categories there now\n",
      "let's go ahead and write those category\n",
      "names although you can get on the pass\n",
      "and M minister's category names there\n",
      "you should get those category names\n",
      "somewhere here\n",
      "yes which category names are here okay\n",
      "so these are the desert trouser pullover\n",
      "dress code sandal cert sneaker back at\n",
      "the ankle board now let's go ahead and\n",
      "and write that the class names here so\n",
      "that we can write in new variable the\n",
      "class name and inside those class name\n",
      "we need to write it\n",
      "okay the desert sign the topic cetera\n",
      "like here we have let us go at the top\n",
      "and the Ender when we have here at\n",
      "rapture and then here we have the\n",
      "pullover and then here we have dress\n",
      "then we have a court and then finally we\n",
      "have the sandal and then we have a cert\n",
      "and then we have a sneaker and then\n",
      "after that we have back sorry it's bad\n",
      "actually not a bad and then we have\n",
      "ankle boot so these are dipped in\n",
      "classes right now let's go ahead and do\n",
      "some the the data exploration so with\n",
      "this data exploration we can actually\n",
      "understand our data in in more explode\n",
      "way okay so since we already have seen\n",
      "its you know the same etc so here if we\n",
      "see the X underscore the train dot say\n",
      "we have 60,000 images but if we see here\n",
      "X underscore test dot safe there we see\n",
      "we have just 10,000 images\n",
      "so this 60,000 images is available for a\n",
      "training and these 10,000 images\n",
      "available for testing purpose so that we\n",
      "can test our model and we can see how\n",
      "accurate our model is performing now let\n",
      "us go ahead and visualize the visualize\n",
      "the data some images so we can visualize\n",
      "that with the PLT so here we have a PLT\n",
      "door failure and then we have a PLT dot\n",
      "image so that's the I am so and inside\n",
      "that we are gonna the see first image\n",
      "okay that is the extreme zero and then\n",
      "I'm gonna just see it and now you will\n",
      "see here it has this image okay so this\n",
      "is actually the boot okay and how would\n",
      "you know this is boot and if we if we\n",
      "print here\n",
      "the X screen actually there you see its\n",
      "nine number and at the nine number you\n",
      "see here we have ankle boot okay so this\n",
      "is the word and if we see here one\n",
      "number and now you see had the one\n",
      "number it's a zero and at the zero it is\n",
      "at top okay so this is how we can\n",
      "visualize and if we print here a color\n",
      "bar at the side okay so we can just\n",
      "right there the color bar okay so with\n",
      "the color bar now you see we have here a\n",
      "color bar and this color bar now you see\n",
      "the value is somewhere in between 0 and\n",
      "the 255 since since neural network model\n",
      "doesn't take the value greater than the\n",
      "one that's mean we need to bring down\n",
      "this the value in the maximum value the\n",
      "255 in between somewhere 0 and 1 so what\n",
      "we can do to bring it down we can just\n",
      "divide the value with 255 I mean the\n",
      "training and the testing data set with\n",
      "the 255 so we can get here with X\n",
      "underscore X underscore train dot sorry\n",
      "X underscore train is equal to X\n",
      "underscore sorry X underscore train and\n",
      "then divide it by two fifty five point\n",
      "zero okay perfect\n",
      "all right so we have got the extreme in\n",
      "between 0 and the 1 and similarly let's\n",
      "go ahead and bring the X test in between\n",
      "0 & 1 which we can get by dividing X\n",
      "test by 255 point 0 so with this we have\n",
      "got our X train and the X test in\n",
      "between and in in between the 0 to 25\n",
      "and what we can do we can just copy it\n",
      "although you need to use your keyboard\n",
      "control and the C and let's go ahead and\n",
      "paste it here and see what happens now\n",
      "now with this you can see here we have\n",
      "brought it down in between 0 and\n",
      "one okay so now this this value is now\n",
      "ready to feed into into into a neural\n",
      "network and one more thing you might\n",
      "have noticed that this size it's a size\n",
      "is 28 cross 28 that's mean there are 28\n",
      "pixels and these are the pixels which\n",
      "you can see okay so these are the pixels\n",
      "a square dot there so these are the 28\n",
      "dots here and the 28 is here okay\n",
      "perfect now let's go ahead now build a\n",
      "model a machine learning model with the\n",
      "tensorflow\n",
      "2.0 with the f 2.0 okay so so so in this\n",
      "what we are going to do the basic\n",
      "building blocks in any neural network is\n",
      "a neural network layers okay so the\n",
      "lyric extracts the representation from\n",
      "the data and Anthony peered into into\n",
      "into it's a hidden layer actually and\n",
      "then finally it starts the training okay\n",
      "so although this is the very critical\n",
      "instance on the tensorflow 2.0 and I'm\n",
      "assuming that you know a little about\n",
      "the neural network so basically you\n",
      "understand how the neural network works\n",
      "so let's go ahead and import the\n",
      "sequential and the dense model\n",
      "sequential and the dense layers from\n",
      "tensorflow Kira's to do that what we can\n",
      "do the front ends are flow from the\n",
      "tensorflow dot Kira's import sequential\n",
      "and then from tensorflow dot dot Kira's\n",
      "and then got layers import and from here\n",
      "I'm gonna import the flatten layer that\n",
      "will be used as a first layer and then\n",
      "dense layer so we have got the two layer\n",
      "and flatten and the dense and the\n",
      "sequential model now let's go ahead and\n",
      "create our model so here we are gonna\n",
      "build\n",
      "our model with the sequential model so\n",
      "here we have a sequence here and then we\n",
      "are gonna pass here ready okay so so the\n",
      "area means the how many are the layers\n",
      "we need inside our sequential model\n",
      "there are many ways to build this but I\n",
      "think this is the simplest way where we\n",
      "can add all these together otherwise\n",
      "there are a few other ways like like\n",
      "just defining first sequential and then\n",
      "going with the model dot add we can go\n",
      "ahead with that one as well like model\n",
      "dot add and then we can add there the\n",
      "first flatten layer there and inside the\n",
      "flatten layer the input shape okay which\n",
      "we are gonna use here input shape will\n",
      "be the 28 cross a 28 there okay so this\n",
      "is an input safe for our the flatten\n",
      "layer the flat hair doesn't do anything\n",
      "actually it's just transformed the the\n",
      "formats of this data which is 28 cross\n",
      "to 28 so this this layer just\n",
      "transformed this data into a one\n",
      "dimensional so that we can fit into the\n",
      "next layer okay so the next layer which\n",
      "I'm gonna add here in the model dot and\n",
      "that is a dense layer okay so this is\n",
      "just a dense layer and inside the dense\n",
      "layer if you press your sift and double\n",
      "tab you will get here detail the\n",
      "documentation on it\n",
      "so in this I'm gonna pass the number of\n",
      "units that's been the number of nodes\n",
      "how many the neural neurons actually we\n",
      "want and then we will pass here the\n",
      "activation function which activation\n",
      "function we are gonna use I'll be taking\n",
      "a different lessons where I will be\n",
      "covering all these things in a very\n",
      "detail this is a very quick lesson so\n",
      "I'm not going to cover all those things\n",
      "here in the detail so activations we\n",
      "will be using and other things we will\n",
      "be just passing as usual okay so other\n",
      "things will be like yeah\n",
      "other things will be a default actually\n",
      "so here in the dense layer I am gonna\n",
      "pass here the 128 new rooms at the\n",
      "firstly and the activation function\n",
      "which we had talked there that I'm gonna\n",
      "use here a raloo activation so this is\n",
      "kind of the detective higher the\n",
      "activation function there are so many\n",
      "other kind of activation function like a\n",
      "sigmoid an edge and you know the\n",
      "Rayleigh key relive all those so here\n",
      "for this listen I'm just gonna use your\n",
      "a loop and then the model dot ad and\n",
      "then again I'm gonna use the output\n",
      "layer in an output layer if you add the\n",
      "output layer then we need to define the\n",
      "how many outputs are there that's when\n",
      "the total number of classes we have a\n",
      "ten classes that's when we have to\n",
      "define here the ten and the activation\n",
      "function here so at the output the real\n",
      "you activation things an activation\n",
      "cannot be used so there at the output\n",
      "either we can use the sigmoid or softmax\n",
      "so here we are gonna use a soft max okay\n",
      "so here we have a model now let's go\n",
      "ahead and print the summary on this\n",
      "model and then you might understand how\n",
      "it is building so the first model has\n",
      "transformed a two-dimensional data into\n",
      "a single dimensional and then here we\n",
      "have 128-bit 128 neurons so 128 and then\n",
      "multiplied by that 784 its complexity\n",
      "reaches the number of parameters\n",
      "actually then reaches to these digits\n",
      "okay so that is the hundred thousands\n",
      "and then finally at the output we are\n",
      "bringing it down to the ten okay jester\n",
      "ten so we have number of parameters at\n",
      "the final output to calculate it the\n",
      "twelve hundred and ninety okay so the\n",
      "total parameter which we which this\n",
      "model will be executing is more than\n",
      "100,000 okay so this is how we build the\n",
      "model now we need to compile our model\n",
      "okay so for compliation of the model\n",
      "there are a few things which are really\n",
      "very important okay the first which need\n",
      "we need to actually define sorry we need\n",
      "to convert it into a markdown\n",
      "yes so the first thing which we need to\n",
      "define is a loss function okay\n",
      "model compliation\n",
      "so to compile the model we need to\n",
      "define the loss function which loss\n",
      "function we want here and then we want\n",
      "optimizer okay and then after optimizer\n",
      "we want here metrics so what are these\n",
      "things a loss function it will measure\n",
      "how accurate the model is during the\n",
      "training and testing then okay actually\n",
      "the loss function minimize minimize the\n",
      "overall error during the training and\n",
      "once the error is minimized during the\n",
      "training then the testing error will be\n",
      "also minimized but that is not always\n",
      "the true because sometimes what happens\n",
      "if your model overpaid then the oral law\n",
      "skit minimized during the training but\n",
      "during the testing it get increased\n",
      "so here the generalization of model is\n",
      "very important that's where optimizer\n",
      "comes so this is how model is updated\n",
      "based on the data that's been the\n",
      "weights of our model applicants updated\n",
      "with the you know as we define the\n",
      "optimizer now let's go ahead and compile\n",
      "this model first so we can compile this\n",
      "with the model dot dot the compiled and\n",
      "then here we have optimizer is equal to\n",
      "Adam and then here we have a loss\n",
      "function there a loss is equal to a\n",
      "spazz categorical okay so there we have\n",
      "a sparse and categorical cross entropy\n",
      "okay\n",
      "and then finally here we have a matrix\n",
      "and inside this matrix we have accuracy\n",
      "okay perfect\n",
      "now let's go ahead and run this and once\n",
      "we run these Suites its of course it's\n",
      "it has compiled there now let's go ahead\n",
      "and train the model for a training a\n",
      "model it is really very simple as we\n",
      "have been doing into our SQL library\n",
      "there we have a mortal dot paid and then\n",
      "here we have X underscore train and then\n",
      "here we have y underscore train and then\n",
      "finally here we have a total number of\n",
      "epochs\n",
      "okay is equal to 10 so with this once we\n",
      "write this it will start suing a\n",
      "progress bar our during the training so\n",
      "the first time at the first epoch itself\n",
      "the accuracy has increased to 82 now do\n",
      "you know the epoch the epoch means at\n",
      "the first time the you know the weights\n",
      "get initialized randomly and when model\n",
      "moves to the second day pork then via\n",
      "back propagation it updates the model\n",
      "that's mean what it is doing at the ten\n",
      "times it is updating the models and then\n",
      "it is running on whole data and each\n",
      "epoch okay that's minify defining your a\n",
      "box is equal to the ten then that so in\n",
      "this model this this model is getting\n",
      "trained ten times on whole data that's\n",
      "mean the weights are getting updated\n",
      "ten times on the whole data now let's go\n",
      "ahead and finally evaluate the accuracy\n",
      "of the model how we can evaluate the\n",
      "accuracy to evaluate the accuracy and\n",
      "the tensorflow has inbuilt model dot he\n",
      "will wait but in this video version that\n",
      "is not working very precisely\n",
      "that's me let's say if I write here a\n",
      "test loss and then the test accuracy is\n",
      "equal to model dot\n",
      "evaluate okay so there it has X\n",
      "underscore test and then Y underscore\n",
      "test okay and then if we print here the\n",
      "test I Chrissy let's go ahead and see\n",
      "how much this tie Chrissy we will get\n",
      "here so this this is a kind of there is\n",
      "a problem I think perhaps that's why it\n",
      "is you know suing these random things\n",
      "although this will take us some time\n",
      "just around return 10 to 20 seconds and\n",
      "then it gets completed and then finally\n",
      "it will the source total accuracy on a\n",
      "test set\n",
      "okay now you see here the tests accuracy\n",
      "on test set has been shown at the end of\n",
      "this that says that the eighty eight\n",
      "point seven five percent of the accuracy\n",
      "Rd test and the total loss is zero point\n",
      "two five\n",
      "now you see here during the training our\n",
      "accuracy was a 91% and at the testing\n",
      "time accuracy is 88% that shows that the\n",
      "overfitting of our model so this is kind\n",
      "of a very simple neural network model\n",
      "just similarly just a single layer is\n",
      "there just a single hidden layer with\n",
      "the 128 neurons so we can expect that\n",
      "this much of the accuracy with this\n",
      "although if we use Union and other\n",
      "networks on this then we definitely we\n",
      "can get a better accuracy okay and on\n",
      "the github it it is claimed that with\n",
      "the CNN we can get around to 99%\n",
      "accuracy in some other lessons we will\n",
      "be also learning it with the CNN as well\n",
      "now let's go ahead and do the prediction\n",
      "with the now let's go ahead and do the\n",
      "prediction with the with the Escalon as\n",
      "well okay so what we can do here with\n",
      "from s killer dot matrix and then here\n",
      "we have import a crazy score okay so now\n",
      "we are we have here we have here\n",
      "accuracy sorry now we need to first get\n",
      "the wipe read as well so that we can get\n",
      "here Y prayer is equal to\n",
      "the wipe rate is equal to the model dot\n",
      "predict okay now you see here we have\n",
      "the two classes actually the predict and\n",
      "the predict classes and the predict\n",
      "probability so the predict will predict\n",
      "a set of the array that will be the\n",
      "continuous value but we need a predict\n",
      "classes so with the predict classes we\n",
      "can get actually what is the predicted\n",
      "class instead of a continuous value on\n",
      "yesterday doesn't that is expressed and\n",
      "then finally let's go ahead and bring it\n",
      "with the accuracy score that here we\n",
      "have y underscore test and then here we\n",
      "have y underscore bread so now you see\n",
      "we have got the accuracy of eighty eight\n",
      "point seven five percent which we have\n",
      "caught with thee with the model dot\n",
      "evaluate although I think there is some\n",
      "bug in this current version of the\n",
      "tensorflow that's why these things we\n",
      "are coming okay\n",
      "perfect now let's go ahead and make a\n",
      "prediction on adjust to some random the\n",
      "random test the image on us just a\n",
      "single image separately and then we will\n",
      "stop this lesson okay to do that what we\n",
      "can do you can just right there let's go\n",
      "ahead with the bread played with the\n",
      "model dot a simple predict and then\n",
      "finally we have here X underscore test\n",
      "now if we print here the bread so the\n",
      "prettiest kind of you know a continuous\n",
      "array that's why I had not done with the\n",
      "predict only that's why I had used here\n",
      "the predict classes and if you see there\n",
      "the wipe read the wipe read here is\n",
      "continuous its its categorical value\n",
      "actually that's been the classes okay so\n",
      "with this now let's go ahead\n",
      "one thing you see and the class has been\n",
      "predicted the first class has been\n",
      "predicted to nine and if you see here\n",
      "the first array the continuous value now\n",
      "you see here at the ninth one okay\n",
      "that's in the tenth class tenth number\n",
      "at the ninth index at the tenth index\n",
      "that's mean you know zero it starts from\n",
      "the zero that's been here nine so it\n",
      "says that at the 98th\n",
      "sent with the confidence of the 98% that\n",
      "it is the ninth okay what we can do now\n",
      "we can prayed here at the zero value now\n",
      "with this you can we see it very clearly\n",
      "okay so this is the maximum out you know\n",
      "the ninth place so that how we can do we\n",
      "can do with the org max here okay so\n",
      "here we have n P dot arcamax there's\n",
      "been the maximum argument at which place\n",
      "there so that's the Preds ero at the\n",
      "plate 0 you see maximum argument at 0th\n",
      "location and similarly we can bring this\n",
      "the maximum prediction at at the first\n",
      "location as well okay so at the first\n",
      "location the maximum is you know the\n",
      "argument - okay perfect so this is the\n",
      "way how we work with the tensorflow 2.0\n",
      "this is all about in this lesson please\n",
      "don't forget to like this video and\n",
      "subscribe this channel so that you can\n",
      "get updates directly into your inbox in\n",
      "further lessons all week also covering\n",
      "more videos on a tensorflow and deep\n",
      "learning till then bye bye and keep\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = '''\n",
    "doesn't Eugene into global variables and\n",
    "05:09\n",
    "the tensorflow 2.0 has also removed this\n",
    "05:12\n",
    "essence the earlier in tensorflow\n",
    "05:15\n",
    "we had to use the system dot run and now\n",
    "05:19\n",
    "the tensorflow 2.0 is kindly kind of\n",
    "05:22\n",
    "bringing it like a function call and\n",
    "05:25\n",
    "moreover now the tensor flew to point X\n",
    "05:29\n",
    "R to find zero brings the clearance at\n",
    "05:33\n",
    "the core of the tensor flow which\n",
    "05:35\n",
    "ultimately increases the you know\n",
    "05:39\n",
    "improves the accuracy that that actually\n",
    "05:43\n",
    "can increase the accuracy but that is\n",
    "05:45\n",
    "not 100% sure that that increases the\n",
    "05:47\n",
    "accuracy but moreover it reduced the\n",
    "05:50\n",
    "training and the testing time since the\n",
    "05:52\n",
    "Kira's has been integrated with the core\n",
    "05:54\n",
    "of the tensor flow and in that case the\n",
    "05:59\n",
    "its execution will be the faster\n",
    "06:01\n",
    "actually and it also takes a less space\n",
    "06:04\n",
    "and moreover it is the consistent and if\n",
    "06:07\n",
    "you want to know more about the tensor\n",
    "06:09\n",
    "flow 2.0 what I it is offering you can\n",
    "06:13\n",
    "go ahead and visit this link it has\n",
    "06:15\n",
    "Google IO link there and at the Google\n",
    "06:18\n",
    "i/o you can you know to see this the\n",
    "06:22\n",
    "complete the getting started with the\n",
    "06:24\n",
    "tensor flow 2.0 at the Google i/o so the\n",
    "06:27\n",
    "air google has released this tensor flow\n",
    "06:29\n",
    "2.0 and they have covered almost\n",
    "06:31\n",
    "everything what is the new in the tensor\n",
    "06:34\n",
    "flow 2.0\n",
    "06:38\n",
    "there are so many things to the new into\n",
    "06:40\n",
    "the tensorflow 2.0 although this is the\n",
    "06:43\n",
    "new video series and we will be learning\n",
    "06:45\n",
    "a lot about the tensorflow\n",
    "06:46\n",
    "2.0 throughout this video series now the\n",
    "06:50\n",
    "let's go ahead the very quickly and I'm\n",
    "06:52\n",
    "assuming that you have already installed\n",
    "06:54\n",
    "the an akuna at the necessary library\n",
    "06:56\n",
    "only you need to install the tensorflow\n",
    "06:59\n",
    "and if you do remember the previously\n",
    "07:01\n",
    "you need to install the chaos and the\n",
    "07:03\n",
    "tensorflow separately but here you only\n",
    "07:06\n",
    "need to install that cancer flow you\n",
    "07:08\n",
    "actually don't need to install the\n",
    "07:10\n",
    "Kiera's so you can call the pip install\n",
    "07:14\n",
    "tensorflow equal to equal to the 2.0 RC\n",
    "07:17\n",
    "and you can go ahead to this github link\n",
    "07:21\n",
    "where you can get the tensorflow the\n",
    "07:24\n",
    "released okay so here we have a\n",
    "07:26\n",
    "tensorflow 2.0 and you can visit that I\n",
    "07:30\n",
    "think with this yes so here we have a\n",
    "07:35\n",
    "you know the latest tensorflow the 2.0\n",
    "07:39\n",
    "this this one is the not the latest one\n",
    "07:41\n",
    "although with the website if you go and\n",
    "07:44\n",
    "visit on the website there you will get\n",
    "07:47\n",
    "a latest one the tensorflow 2.0 the\n",
    "07:50\n",
    "release candidate is available and you\n",
    "07:52\n",
    "just go ahead there you will get the\n",
    "07:54\n",
    "link here to install this so you can\n",
    "07:57\n",
    "keep monitoring this mission this link\n",
    "08:00\n",
    "to get the updated version by the time\n",
    "08:04\n",
    "I'm making this video this is the latest\n",
    "08:06\n",
    "version now let's go ahead and open\n",
    "08:09\n",
    "anaconda into administrator mode\n",
    "08:11\n",
    "remember you need to open it into the\n",
    "08:13\n",
    "administrator mode otherwise it would\n",
    "08:16\n",
    "not be able to install the tensorflow\n",
    "08:18\n",
    "2.0 in your computer because of the\n",
    "08:21\n",
    "right permission now let's go ahead and\n",
    "08:25\n",
    "copy this which I can just copy it and\n",
    "08:31\n",
    "in the anaconda right the pressing the\n",
    "08:35\n",
    "right click it will paste here the PIP\n",
    "08:37\n",
    "installed tensorflow equal to equal to\n",
    "08:39\n",
    "two point zero point zero RC 0 that if\n",
    "08:43\n",
    "the release candidate 0 let's go ahead\n",
    "08:45\n",
    "and hit the enter although I have\n",
    "08:47\n",
    "already installed the tensorflow 2.0\n",
    "08:49\n",
    "that's why it is saying that the\n",
    "08:51\n",
    "all the requirement has been already\n",
    "08:53\n",
    "satisfied but if you do not have the\n",
    "08:56\n",
    "tensorflow 2.0 installed in your\n",
    "08:58\n",
    "computer you can install and the\n",
    "09:00\n",
    "moreover if you get the any error then\n",
    "09:02\n",
    "you can first uninstall the previous\n",
    "09:05\n",
    "tensorflow for that you can right there\n",
    "09:08\n",
    "pip uninstalled tensorflow so it will\n",
    "09:12\n",
    "uninstall your previous versions and\n",
    "09:14\n",
    "then you can install a new version of a\n",
    "09:16\n",
    "tensorflow\n",
    "09:17\n",
    "okay perfect now let's go ahead and see\n",
    "09:22\n",
    "if you have a GPU in your computer then\n",
    "09:25\n",
    "you can also install a GPU version of a\n",
    "09:28\n",
    "tensorflow\n",
    "09:29\n",
    "right so these are the two ways where\n",
    "09:31\n",
    "you can install a tensorflow in your\n",
    "09:33\n",
    "computer now you can pause the video and\n",
    "09:36\n",
    "pause this video and that you can\n",
    "09:39\n",
    "continue this video after installing the\n",
    "09:41\n",
    "tensorflow\n",
    "09:42\n",
    "2.0 alright now let's go ahead import\n",
    "09:46\n",
    "the fashion mms data set so in this\n",
    "09:49\n",
    "lesson we will be working on the finest\n",
    "09:51\n",
    "fashion m-miss data set the fashion m\n",
    "09:55\n",
    "needs to data set the link is available\n",
    "09:56\n",
    "here and this working we working file is\n",
    "10:00\n",
    "available in the video description from\n",
    "10:02\n",
    "where you can download and if you visit\n",
    "10:04\n",
    "this fashion m niche then you see here\n",
    "10:06\n",
    "on the github the link is available and\n",
    "10:10\n",
    "on the github it says that this is\n",
    "10:14\n",
    "Jolanda article images it has 60\n",
    "10:16\n",
    "thousands examples and every sample have\n",
    "10:20\n",
    "20 28 cross 28 grayscale images and so\n",
    "10:26\n",
    "these are the images and it has a 10\n",
    "10:28\n",
    "actually it has two total the ten\n",
    "10:32\n",
    "classes and that's mean there are 10\n",
    "10:35\n",
    "type of the the fashion images are of\n",
    "10:38\n",
    "level in this fashion amidst dataset\n",
    "10:41\n",
    "okay so these are the images which are\n",
    "10:44\n",
    "available and and and and this sixty\n",
    "10:49\n",
    "thousand images which we will be using\n",
    "10:51\n",
    "to train and ten thousand images to\n",
    "10:56\n",
    "we'll be using to evaluate and it has\n",
    "10:59\n",
    "total the ten categories of these images\n",
    "11:02\n",
    "ok now let's go ahead\n",
    "11:05\n",
    "and first import our learner now first\n",
    "11:12\n",
    "let's go ahead and import the tensorflow\n",
    "11:13\n",
    "and then I'll show you how you can\n",
    "11:16\n",
    "download this the amnesty data set\n",
    "11:20\n",
    "directly into your Jupiters notebook\n",
    "11:22\n",
    "instead of downloading it from a geek\n",
    "11:24\n",
    "health ok / pets to import the\n",
    "11:27\n",
    "tensorflow you need to write their the\n",
    "11:29\n",
    "import and then the tensorflow\n",
    "11:34\n",
    "there we have a tensor flow as usual\n",
    "11:37\n",
    "tensor flow as DF and then we need to\n",
    "11:42\n",
    "improve the care as from the tensor flow\n",
    "11:44\n",
    "so here we have a from tensor flow\n",
    "11:49\n",
    "import the Kira's okay so now we have\n",
    "11:55\n",
    "got sorry we have got the tensor flow\n",
    "12:00\n",
    "and in the chaos sorry yeah now we have\n",
    "12:08\n",
    "imported the Kira's from a tensor flow\n",
    "12:10\n",
    "now let's go ahead and import other\n",
    "12:12\n",
    "necessary libraries like numpy pandas\n",
    "12:15\n",
    "and the matplotlib so those things we\n",
    "12:17\n",
    "can say that a helper liability but\n",
    "12:19\n",
    "before that let's go ahead and check a\n",
    "12:21\n",
    "tensor flow version which you can just\n",
    "12:23\n",
    "check from a print T F dot version so\n",
    "12:30\n",
    "this says that we have Overson 2.0\n",
    "12:32\n",
    "installed in my computer now let's go\n",
    "12:35\n",
    "ahead and import helper libraries like\n",
    "12:37\n",
    "an umpire Pentagon the matplotlib so in\n",
    "12:40\n",
    "the previous videos we have been\n",
    "12:41\n",
    "importing these libraries very\n",
    "12:44\n",
    "frequently numpy as in P and import\n",
    "12:51\n",
    "pandas HPD and then import might float\n",
    "12:57\n",
    "lib dot type lot as PLT so here we have\n",
    "13:03\n",
    "matplotlib i the pandas and the numpy\n",
    "13:06\n",
    "imported in our computer so these things\n",
    "13:08\n",
    "we can treat as a helper libraries now\n",
    "13:11\n",
    "let's go ahead and load the amnesty\n",
    "13:13\n",
    "person dataset so for that i can write\n",
    "13:16\n",
    "here the amidst is equal to\n",
    "13:19\n",
    "the Kyra's dot datasets and then I can\n",
    "13:24\n",
    "write there the fashion I'm honest so\n",
    "13:26\n",
    "with this we will get a pass anemones\n",
    "13:28\n",
    "dataset although I have already\n",
    "13:30\n",
    "downloaded it my computer otherwise it\n",
    "13:32\n",
    "might take a little time in your\n",
    "13:34\n",
    "computer to download this data set from\n",
    "13:36\n",
    "a internet that might take a few seconds\n",
    "13:39\n",
    "if you have a fast internet now let's go\n",
    "13:41\n",
    "ahead and check the type of the\n",
    "13:43\n",
    "immunised this says that with this\n",
    "13:47\n",
    "immunised actually it has downloaded the\n",
    "13:49\n",
    "data sets in a tensor flow module\n",
    "13:52\n",
    "wrapper now what we need to do now we\n",
    "13:54\n",
    "need to actually load the data now we\n",
    "13:57\n",
    "need to load this data into into a real\n",
    "14:01\n",
    "real variables in this jupiter notebook\n",
    "14:05\n",
    "and to do that it actually returns a\n",
    "14:07\n",
    "tuple ok the two tuples wonderful for\n",
    "14:09\n",
    "the training and another tougher for the\n",
    "14:11\n",
    "testing so for this what we can do here\n",
    "14:14\n",
    "the m in each dot a load data set as\n",
    "14:17\n",
    "usual we have been doing into a scalar\n",
    "14:19\n",
    "now in this topple we need to first down\n",
    "14:22\n",
    "get the data into our our the training\n",
    "14:25\n",
    "dataset that is the extreme and then\n",
    "14:28\n",
    "finally Whiterun and the next couple in\n",
    "14:32\n",
    "the next it returns the testing data\n",
    "14:35\n",
    "sets it has X underscore test and then Y\n",
    "14:38\n",
    "underscore test so it has a 60,000 rows\n",
    "14:42\n",
    "for a training which we can verify that\n",
    "14:47\n",
    "with X train dot safe now there you see\n",
    "14:50\n",
    "here there are 60,000 images are\n",
    "14:55\n",
    "available there and each images have 28\n",
    "14:57\n",
    "cross 28 some since there are 60,000\n",
    "15:02\n",
    "images that's mean it should have a\n",
    "15:04\n",
    "60,000 y train as well so let's go ahead\n",
    "15:07\n",
    "and check the safe of Y trend which says\n",
    "15:09\n",
    "that it has a 60,000 okay now let's go\n",
    "15:13\n",
    "ahead and print the X train and see what\n",
    "15:16\n",
    "happens\n",
    "15:16\n",
    "once we print the extreme we see the\n",
    "15:19\n",
    "values the most of the values we are\n",
    "15:21\n",
    "printing here 0 that is because you note\n",
    "15:24\n",
    "at the ages since this is the grayscale\n",
    "15:27\n",
    "so at the edges the most of the images\n",
    "15:30\n",
    "values are 0\n",
    "15:32\n",
    "otherwise the maximum value inside this\n",
    "15:34\n",
    "the area which we can find that within P\n",
    "15:38\n",
    "dot max okay so that's it the 255 so the\n",
    "15:44\n",
    "minimum we have already seen in there\n",
    "15:46\n",
    "and that that is the zero but here are\n",
    "15:49\n",
    "the max is 255 and if we see the average\n",
    "15:53\n",
    "that's mean the N P dot mean the X train\n",
    "15:59\n",
    "so it says that something so moreover\n",
    "16:01\n",
    "now we can we can say that the values is\n",
    "16:05\n",
    "somewhere in between 0 and the 255 okay\n",
    "16:08\n",
    "inside this data set which we later we\n",
    "16:11\n",
    "need to bring down in between 0 and 1 to\n",
    "16:14\n",
    "train with the tensor flow tensor flow\n",
    "16:17\n",
    "model okay our deep learning model and\n",
    "16:20\n",
    "these 60,000 images are classified into\n",
    "16:23\n",
    "ten labels and those labels are encoded\n",
    "16:28\n",
    "into a numerical values and those\n",
    "16:30\n",
    "numerical values we can see with the Y\n",
    "16:32\n",
    "under escort rain and those numerical\n",
    "16:35\n",
    "values are in between 0 & 1 sorry 0 1 9\n",
    "16:39\n",
    "okay so it starts from the 0 until the 9\n",
    "16:42\n",
    "so those are the 10 categories there now\n",
    "16:45\n",
    "let's go ahead and write those category\n",
    "16:47\n",
    "names although you can get on the pass\n",
    "16:49\n",
    "and M minister's category names there\n",
    "16:51\n",
    "you should get those category names\n",
    "16:54\n",
    "somewhere here\n",
    "16:55\n",
    "yes which category names are here okay\n",
    "16:58\n",
    "so these are the desert trouser pullover\n",
    "17:01\n",
    "dress code sandal cert sneaker back at\n",
    "17:05\n",
    "the ankle board now let's go ahead and\n",
    "17:08\n",
    "and write that the class names here so\n",
    "17:13\n",
    "that we can write in new variable the\n",
    "17:15\n",
    "class name and inside those class name\n",
    "17:18\n",
    "we need to write it\n",
    "17:20\n",
    "okay the desert sign the topic cetera\n",
    "17:25\n",
    "like here we have let us go at the top\n",
    "17:28\n",
    "and the Ender when we have here at\n",
    "17:31\n",
    "rapture and then here we have the\n",
    "17:36\n",
    "pullover and then here we have dress\n",
    "17:42\n",
    "then we have a court and then finally we\n",
    "17:46\n",
    "have the sandal and then we have a cert\n",
    "17:53\n",
    "and then we have a sneaker and then\n",
    "17:59\n",
    "after that we have back sorry it's bad\n",
    "18:03\n",
    "actually not a bad and then we have\n",
    "18:08\n",
    "ankle boot so these are dipped in\n",
    "18:12\n",
    "classes right now let's go ahead and do\n",
    "18:15\n",
    "some the the data exploration so with\n",
    "18:25\n",
    "this data exploration we can actually\n",
    "18:27\n",
    "understand our data in in more explode\n",
    "18:32\n",
    "way okay so since we already have seen\n",
    "18:37\n",
    "its you know the same etc so here if we\n",
    "18:40\n",
    "see the X underscore the train dot say\n",
    "18:45\n",
    "we have 60,000 images but if we see here\n",
    "18:50\n",
    "X underscore test dot safe there we see\n",
    "18:54\n",
    "we have just 10,000 images\n",
    "18:55\n",
    "so this 60,000 images is available for a\n",
    "18:59\n",
    "training and these 10,000 images\n",
    "19:00\n",
    "available for testing purpose so that we\n",
    "19:04\n",
    "can test our model and we can see how\n",
    "19:07\n",
    "accurate our model is performing now let\n",
    "19:10\n",
    "us go ahead and visualize the visualize\n",
    "19:14\n",
    "the data some images so we can visualize\n",
    "19:18\n",
    "that with the PLT so here we have a PLT\n",
    "19:22\n",
    "door failure and then we have a PLT dot\n",
    "19:27\n",
    "image so that's the I am so and inside\n",
    "19:32\n",
    "that we are gonna the see first image\n",
    "19:36\n",
    "okay that is the extreme zero and then\n",
    "19:40\n",
    "I'm gonna just see it and now you will\n",
    "19:43\n",
    "see here it has this image okay so this\n",
    "19:47\n",
    "is actually the boot okay and how would\n",
    "19:50\n",
    "you know this is boot and if we if we\n",
    "19:55\n",
    "print here\n",
    "19:56\n",
    "the X screen actually there you see its\n",
    "19:59\n",
    "nine number and at the nine number you\n",
    "20:02\n",
    "see here we have ankle boot okay so this\n",
    "20:05\n",
    "is the word and if we see here one\n",
    "20:08\n",
    "number and now you see had the one\n",
    "20:10\n",
    "number it's a zero and at the zero it is\n",
    "20:13\n",
    "at top okay so this is how we can\n",
    "20:16\n",
    "visualize and if we print here a color\n",
    "20:18\n",
    "bar at the side okay so we can just\n",
    "20:21\n",
    "right there the color bar okay so with\n",
    "20:25\n",
    "the color bar now you see we have here a\n",
    "20:28\n",
    "color bar and this color bar now you see\n",
    "20:30\n",
    "the value is somewhere in between 0 and\n",
    "20:33\n",
    "the 255 since since neural network model\n",
    "20:38\n",
    "doesn't take the value greater than the\n",
    "20:40\n",
    "one that's mean we need to bring down\n",
    "20:42\n",
    "this the value in the maximum value the\n",
    "20:44\n",
    "255 in between somewhere 0 and 1 so what\n",
    "20:49\n",
    "we can do to bring it down we can just\n",
    "20:51\n",
    "divide the value with 255 I mean the\n",
    "20:54\n",
    "training and the testing data set with\n",
    "20:56\n",
    "the 255 so we can get here with X\n",
    "21:00\n",
    "underscore X underscore train dot sorry\n",
    "21:08\n",
    "X underscore train is equal to X\n",
    "21:10\n",
    "underscore sorry X underscore train and\n",
    "21:15\n",
    "then divide it by two fifty five point\n",
    "21:19\n",
    "zero okay perfect\n",
    "21:21\n",
    "all right so we have got the extreme in\n",
    "21:26\n",
    "between 0 and the 1 and similarly let's\n",
    "21:28\n",
    "go ahead and bring the X test in between\n",
    "21:32\n",
    "0 & 1 which we can get by dividing X\n",
    "21:35\n",
    "test by 255 point 0 so with this we have\n",
    "21:43\n",
    "got our X train and the X test in\n",
    "21:46\n",
    "between and in in between the 0 to 25\n",
    "21:51\n",
    "and what we can do we can just copy it\n",
    "21:54\n",
    "although you need to use your keyboard\n",
    "21:56\n",
    "control and the C and let's go ahead and\n",
    "21:59\n",
    "paste it here and see what happens now\n",
    "22:02\n",
    "now with this you can see here we have\n",
    "22:06\n",
    "brought it down in between 0 and\n",
    "22:09\n",
    "one okay so now this this value is now\n",
    "22:13\n",
    "ready to feed into into into a neural\n",
    "22:17\n",
    "network and one more thing you might\n",
    "22:20\n",
    "have noticed that this size it's a size\n",
    "22:22\n",
    "is 28 cross 28 that's mean there are 28\n",
    "22:26\n",
    "pixels and these are the pixels which\n",
    "22:28\n",
    "you can see okay so these are the pixels\n",
    "22:31\n",
    "a square dot there so these are the 28\n",
    "22:34\n",
    "dots here and the 28 is here okay\n",
    "22:37\n",
    "perfect now let's go ahead now build a\n",
    "22:40\n",
    "model a machine learning model with the\n",
    "22:44\n",
    "tensorflow\n",
    "22:45\n",
    "2.0 with the f 2.0 okay so so so in this\n",
    "22:59\n",
    "what we are going to do the basic\n",
    "23:01\n",
    "building blocks in any neural network is\n",
    "23:04\n",
    "a neural network layers okay so the\n",
    "23:08\n",
    "lyric extracts the representation from\n",
    "23:10\n",
    "the data and Anthony peered into into\n",
    "23:15\n",
    "into it's a hidden layer actually and\n",
    "23:17\n",
    "then finally it starts the training okay\n",
    "23:21\n",
    "so although this is the very critical\n",
    "23:23\n",
    "instance on the tensorflow 2.0 and I'm\n",
    "23:27\n",
    "assuming that you know a little about\n",
    "23:28\n",
    "the neural network so basically you\n",
    "23:31\n",
    "understand how the neural network works\n",
    "23:33\n",
    "so let's go ahead and import the\n",
    "23:36\n",
    "sequential and the dense model\n",
    "23:38\n",
    "sequential and the dense layers from\n",
    "23:41\n",
    "tensorflow Kira's to do that what we can\n",
    "23:44\n",
    "do the front ends are flow from the\n",
    "23:47\n",
    "tensorflow dot Kira's import sequential\n",
    "23:52\n",
    "and then from tensorflow dot dot Kira's\n",
    "24:01\n",
    "and then got layers import and from here\n",
    "24:06\n",
    "I'm gonna import the flatten layer that\n",
    "24:10\n",
    "will be used as a first layer and then\n",
    "24:13\n",
    "dense layer so we have got the two layer\n",
    "24:15\n",
    "and flatten and the dense and the\n",
    "24:17\n",
    "sequential model now let's go ahead and\n",
    "24:20\n",
    "create our model so here we are gonna\n",
    "24:23\n",
    "build\n",
    "24:23\n",
    "our model with the sequential model so\n",
    "24:26\n",
    "here we have a sequence here and then we\n",
    "24:31\n",
    "are gonna pass here ready okay so so the\n",
    "24:35\n",
    "area means the how many are the layers\n",
    "24:37\n",
    "we need inside our sequential model\n",
    "24:40\n",
    "there are many ways to build this but I\n",
    "24:43\n",
    "think this is the simplest way where we\n",
    "24:45\n",
    "can add all these together otherwise\n",
    "24:48\n",
    "there are a few other ways like like\n",
    "24:50\n",
    "just defining first sequential and then\n",
    "24:53\n",
    "going with the model dot add we can go\n",
    "24:56\n",
    "ahead with that one as well like model\n",
    "24:58\n",
    "dot add and then we can add there the\n",
    "25:01\n",
    "first flatten layer there and inside the\n",
    "25:04\n",
    "flatten layer the input shape okay which\n",
    "25:08\n",
    "we are gonna use here input shape will\n",
    "25:11\n",
    "be the 28 cross a 28 there okay so this\n",
    "25:16\n",
    "is an input safe for our the flatten\n",
    "25:20\n",
    "layer the flat hair doesn't do anything\n",
    "25:23\n",
    "actually it's just transformed the the\n",
    "25:26\n",
    "formats of this data which is 28 cross\n",
    "25:29\n",
    "to 28 so this this layer just\n",
    "25:31\n",
    "transformed this data into a one\n",
    "25:34\n",
    "dimensional so that we can fit into the\n",
    "25:36\n",
    "next layer okay so the next layer which\n",
    "25:38\n",
    "I'm gonna add here in the model dot and\n",
    "25:41\n",
    "that is a dense layer okay so this is\n",
    "25:46\n",
    "just a dense layer and inside the dense\n",
    "25:48\n",
    "layer if you press your sift and double\n",
    "25:50\n",
    "tab you will get here detail the\n",
    "25:52\n",
    "documentation on it\n",
    "25:53\n",
    "so in this I'm gonna pass the number of\n",
    "25:56\n",
    "units that's been the number of nodes\n",
    "25:58\n",
    "how many the neural neurons actually we\n",
    "26:02\n",
    "want and then we will pass here the\n",
    "26:05\n",
    "activation function which activation\n",
    "26:07\n",
    "function we are gonna use I'll be taking\n",
    "26:10\n",
    "a different lessons where I will be\n",
    "26:11\n",
    "covering all these things in a very\n",
    "26:13\n",
    "detail this is a very quick lesson so\n",
    "26:15\n",
    "I'm not going to cover all those things\n",
    "26:16\n",
    "here in the detail so activations we\n",
    "26:19\n",
    "will be using and other things we will\n",
    "26:21\n",
    "be just passing as usual okay so other\n",
    "26:25\n",
    "things will be like yeah\n",
    "26:28\n",
    "other things will be a default actually\n",
    "26:30\n",
    "so here in the dense layer I am gonna\n",
    "26:33\n",
    "pass here the 128 new rooms at the\n",
    "26:36\n",
    "firstly and the activation function\n",
    "26:39\n",
    "which we had talked there that I'm gonna\n",
    "26:42\n",
    "use here a raloo activation so this is\n",
    "26:44\n",
    "kind of the detective higher the\n",
    "26:47\n",
    "activation function there are so many\n",
    "26:50\n",
    "other kind of activation function like a\n",
    "26:52\n",
    "sigmoid an edge and you know the\n",
    "26:55\n",
    "Rayleigh key relive all those so here\n",
    "26:58\n",
    "for this listen I'm just gonna use your\n",
    "27:00\n",
    "a loop and then the model dot ad and\n",
    "27:03\n",
    "then again I'm gonna use the output\n",
    "27:05\n",
    "layer in an output layer if you add the\n",
    "27:09\n",
    "output layer then we need to define the\n",
    "27:12\n",
    "how many outputs are there that's when\n",
    "27:14\n",
    "the total number of classes we have a\n",
    "27:16\n",
    "ten classes that's when we have to\n",
    "27:18\n",
    "define here the ten and the activation\n",
    "27:21\n",
    "function here so at the output the real\n",
    "27:25\n",
    "you activation things an activation\n",
    "27:26\n",
    "cannot be used so there at the output\n",
    "27:29\n",
    "either we can use the sigmoid or softmax\n",
    "27:32\n",
    "so here we are gonna use a soft max okay\n",
    "27:37\n",
    "so here we have a model now let's go\n",
    "27:39\n",
    "ahead and print the summary on this\n",
    "27:41\n",
    "model and then you might understand how\n",
    "27:45\n",
    "it is building so the first model has\n",
    "27:48\n",
    "transformed a two-dimensional data into\n",
    "27:50\n",
    "a single dimensional and then here we\n",
    "27:53\n",
    "have 128-bit 128 neurons so 128 and then\n",
    "27:58\n",
    "multiplied by that 784 its complexity\n",
    "28:02\n",
    "reaches the number of parameters\n",
    "28:04\n",
    "actually then reaches to these digits\n",
    "28:06\n",
    "okay so that is the hundred thousands\n",
    "28:09\n",
    "and then finally at the output we are\n",
    "28:12\n",
    "bringing it down to the ten okay jester\n",
    "28:15\n",
    "ten so we have number of parameters at\n",
    "28:17\n",
    "the final output to calculate it the\n",
    "28:19\n",
    "twelve hundred and ninety okay so the\n",
    "28:22\n",
    "total parameter which we which this\n",
    "28:24\n",
    "model will be executing is more than\n",
    "28:26\n",
    "100,000 okay so this is how we build the\n",
    "28:31\n",
    "model now we need to compile our model\n",
    "28:34\n",
    "okay so for compliation of the model\n",
    "28:37\n",
    "there are a few things which are really\n",
    "28:38\n",
    "very important okay the first which need\n",
    "28:42\n",
    "we need to actually define sorry we need\n",
    "28:46\n",
    "to convert it into a markdown\n",
    "28:49\n",
    "yes so the first thing which we need to\n",
    "28:51\n",
    "define is a loss function okay\n",
    "29:08\n",
    "model compliation\n",
    "29:11\n",
    "so to compile the model we need to\n",
    "29:13\n",
    "define the loss function which loss\n",
    "29:15\n",
    "function we want here and then we want\n",
    "29:18\n",
    "optimizer okay and then after optimizer\n",
    "29:22\n",
    "we want here metrics so what are these\n",
    "29:26\n",
    "things a loss function it will measure\n",
    "29:31\n",
    "how accurate the model is during the\n",
    "29:33\n",
    "training and testing then okay actually\n",
    "29:38\n",
    "the loss function minimize minimize the\n",
    "29:40\n",
    "overall error during the training and\n",
    "29:42\n",
    "once the error is minimized during the\n",
    "29:45\n",
    "training then the testing error will be\n",
    "29:48\n",
    "also minimized but that is not always\n",
    "29:52\n",
    "the true because sometimes what happens\n",
    "29:55\n",
    "if your model overpaid then the oral law\n",
    "29:58\n",
    "skit minimized during the training but\n",
    "30:01\n",
    "during the testing it get increased\n",
    "30:03\n",
    "so here the generalization of model is\n",
    "30:05\n",
    "very important that's where optimizer\n",
    "30:08\n",
    "comes so this is how model is updated\n",
    "30:10\n",
    "based on the data that's been the\n",
    "30:12\n",
    "weights of our model applicants updated\n",
    "30:15\n",
    "with the you know as we define the\n",
    "30:19\n",
    "optimizer now let's go ahead and compile\n",
    "30:21\n",
    "this model first so we can compile this\n",
    "30:24\n",
    "with the model dot dot the compiled and\n",
    "30:30\n",
    "then here we have optimizer is equal to\n",
    "30:33\n",
    "Adam and then here we have a loss\n",
    "30:37\n",
    "function there a loss is equal to a\n",
    "30:42\n",
    "spazz categorical okay so there we have\n",
    "30:46\n",
    "a sparse and categorical cross entropy\n",
    "30:57\n",
    "okay\n",
    "30:59\n",
    "and then finally here we have a matrix\n",
    "31:02\n",
    "and inside this matrix we have accuracy\n",
    "31:10\n",
    "okay perfect\n",
    "31:12\n",
    "now let's go ahead and run this and once\n",
    "31:16\n",
    "we run these Suites its of course it's\n",
    "31:18\n",
    "it has compiled there now let's go ahead\n",
    "31:20\n",
    "and train the model for a training a\n",
    "31:23\n",
    "model it is really very simple as we\n",
    "31:25\n",
    "have been doing into our SQL library\n",
    "31:27\n",
    "there we have a mortal dot paid and then\n",
    "31:32\n",
    "here we have X underscore train and then\n",
    "31:35\n",
    "here we have y underscore train and then\n",
    "31:41\n",
    "finally here we have a total number of\n",
    "31:43\n",
    "epochs\n",
    "31:44\n",
    "okay is equal to 10 so with this once we\n",
    "31:49\n",
    "write this it will start suing a\n",
    "31:52\n",
    "progress bar our during the training so\n",
    "31:56\n",
    "the first time at the first epoch itself\n",
    "31:58\n",
    "the accuracy has increased to 82 now do\n",
    "32:02\n",
    "you know the epoch the epoch means at\n",
    "32:04\n",
    "the first time the you know the weights\n",
    "32:08\n",
    "get initialized randomly and when model\n",
    "32:11\n",
    "moves to the second day pork then via\n",
    "32:14\n",
    "back propagation it updates the model\n",
    "32:16\n",
    "that's mean what it is doing at the ten\n",
    "32:19\n",
    "times it is updating the models and then\n",
    "32:22\n",
    "it is running on whole data and each\n",
    "32:25\n",
    "epoch okay that's minify defining your a\n",
    "32:28\n",
    "box is equal to the ten then that so in\n",
    "32:31\n",
    "this model this this model is getting\n",
    "32:34\n",
    "trained ten times on whole data that's\n",
    "32:37\n",
    "mean the weights are getting updated\n",
    "32:39\n",
    "ten times on the whole data now let's go\n",
    "32:43\n",
    "ahead and finally evaluate the accuracy\n",
    "32:46\n",
    "of the model how we can evaluate the\n",
    "32:48\n",
    "accuracy to evaluate the accuracy and\n",
    "32:52\n",
    "the tensorflow has inbuilt model dot he\n",
    "32:54\n",
    "will wait but in this video version that\n",
    "32:56\n",
    "is not working very precisely\n",
    "32:59\n",
    "that's me let's say if I write here a\n",
    "33:01\n",
    "test loss and then the test accuracy is\n",
    "33:07\n",
    "equal to model dot\n",
    "33:10\n",
    "evaluate okay so there it has X\n",
    "33:14\n",
    "underscore test and then Y underscore\n",
    "33:18\n",
    "test okay and then if we print here the\n",
    "33:24\n",
    "test I Chrissy let's go ahead and see\n",
    "33:26\n",
    "how much this tie Chrissy we will get\n",
    "33:28\n",
    "here so this this is a kind of there is\n",
    "33:33\n",
    "a problem I think perhaps that's why it\n",
    "33:35\n",
    "is you know suing these random things\n",
    "33:37\n",
    "although this will take us some time\n",
    "33:39\n",
    "just around return 10 to 20 seconds and\n",
    "33:42\n",
    "then it gets completed and then finally\n",
    "33:44\n",
    "it will the source total accuracy on a\n",
    "33:48\n",
    "test set\n",
    "33:49\n",
    "okay now you see here the tests accuracy\n",
    "33:52\n",
    "on test set has been shown at the end of\n",
    "33:55\n",
    "this that says that the eighty eight\n",
    "33:57\n",
    "point seven five percent of the accuracy\n",
    "33:59\n",
    "Rd test and the total loss is zero point\n",
    "34:03\n",
    "two five\n",
    "34:04\n",
    "now you see here during the training our\n",
    "34:07\n",
    "accuracy was a 91% and at the testing\n",
    "34:10\n",
    "time accuracy is 88% that shows that the\n",
    "34:12\n",
    "overfitting of our model so this is kind\n",
    "34:15\n",
    "of a very simple neural network model\n",
    "34:17\n",
    "just similarly just a single layer is\n",
    "34:20\n",
    "there just a single hidden layer with\n",
    "34:23\n",
    "the 128 neurons so we can expect that\n",
    "34:26\n",
    "this much of the accuracy with this\n",
    "34:28\n",
    "although if we use Union and other\n",
    "34:31\n",
    "networks on this then we definitely we\n",
    "34:33\n",
    "can get a better accuracy okay and on\n",
    "34:36\n",
    "the github it it is claimed that with\n",
    "34:38\n",
    "the CNN we can get around to 99%\n",
    "34:41\n",
    "accuracy in some other lessons we will\n",
    "34:43\n",
    "be also learning it with the CNN as well\n",
    "34:46\n",
    "now let's go ahead and do the prediction\n",
    "34:48\n",
    "with the now let's go ahead and do the\n",
    "34:53\n",
    "prediction with the with the Escalon as\n",
    "34:58\n",
    "well okay so what we can do here with\n",
    "35:00\n",
    "from s killer dot matrix and then here\n",
    "35:07\n",
    "we have import a crazy score okay so now\n",
    "35:13\n",
    "we are we have here we have here\n",
    "35:15\n",
    "accuracy sorry now we need to first get\n",
    "35:18\n",
    "the wipe read as well so that we can get\n",
    "35:21\n",
    "here Y prayer is equal to\n",
    "35:24\n",
    "the wipe rate is equal to the model dot\n",
    "35:30\n",
    "predict okay now you see here we have\n",
    "35:32\n",
    "the two classes actually the predict and\n",
    "35:34\n",
    "the predict classes and the predict\n",
    "35:36\n",
    "probability so the predict will predict\n",
    "35:39\n",
    "a set of the array that will be the\n",
    "35:41\n",
    "continuous value but we need a predict\n",
    "35:43\n",
    "classes so with the predict classes we\n",
    "35:46\n",
    "can get actually what is the predicted\n",
    "35:48\n",
    "class instead of a continuous value on\n",
    "35:51\n",
    "yesterday doesn't that is expressed and\n",
    "35:54\n",
    "then finally let's go ahead and bring it\n",
    "35:57\n",
    "with the accuracy score that here we\n",
    "36:00\n",
    "have y underscore test and then here we\n",
    "36:03\n",
    "have y underscore bread so now you see\n",
    "36:06\n",
    "we have got the accuracy of eighty eight\n",
    "36:08\n",
    "point seven five percent which we have\n",
    "36:11\n",
    "caught with thee with the model dot\n",
    "36:13\n",
    "evaluate although I think there is some\n",
    "36:15\n",
    "bug in this current version of the\n",
    "36:17\n",
    "tensorflow that's why these things we\n",
    "36:18\n",
    "are coming okay\n",
    "36:20\n",
    "perfect now let's go ahead and make a\n",
    "36:25\n",
    "prediction on adjust to some random the\n",
    "36:28\n",
    "random test the image on us just a\n",
    "36:30\n",
    "single image separately and then we will\n",
    "36:32\n",
    "stop this lesson okay to do that what we\n",
    "36:35\n",
    "can do you can just right there let's go\n",
    "36:38\n",
    "ahead with the bread played with the\n",
    "36:40\n",
    "model dot a simple predict and then\n",
    "36:44\n",
    "finally we have here X underscore test\n",
    "36:46\n",
    "now if we print here the bread so the\n",
    "36:49\n",
    "prettiest kind of you know a continuous\n",
    "36:51\n",
    "array that's why I had not done with the\n",
    "36:54\n",
    "predict only that's why I had used here\n",
    "36:56\n",
    "the predict classes and if you see there\n",
    "37:00\n",
    "the wipe read the wipe read here is\n",
    "37:03\n",
    "continuous its its categorical value\n",
    "37:07\n",
    "actually that's been the classes okay so\n",
    "37:10\n",
    "with this now let's go ahead\n",
    "37:12\n",
    "one thing you see and the class has been\n",
    "37:15\n",
    "predicted the first class has been\n",
    "37:16\n",
    "predicted to nine and if you see here\n",
    "37:18\n",
    "the first array the continuous value now\n",
    "37:22\n",
    "you see here at the ninth one okay\n",
    "37:24\n",
    "that's in the tenth class tenth number\n",
    "37:26\n",
    "at the ninth index at the tenth index\n",
    "37:30\n",
    "that's mean you know zero it starts from\n",
    "37:33\n",
    "the zero that's been here nine so it\n",
    "37:35\n",
    "says that at the 98th\n",
    "37:37\n",
    "sent with the confidence of the 98% that\n",
    "37:40\n",
    "it is the ninth okay what we can do now\n",
    "37:43\n",
    "we can prayed here at the zero value now\n",
    "37:47\n",
    "with this you can we see it very clearly\n",
    "37:49\n",
    "okay so this is the maximum out you know\n",
    "37:53\n",
    "the ninth place so that how we can do we\n",
    "37:59\n",
    "can do with the org max here okay so\n",
    "38:02\n",
    "here we have n P dot arcamax there's\n",
    "38:05\n",
    "been the maximum argument at which place\n",
    "38:07\n",
    "there so that's the Preds ero at the\n",
    "38:10\n",
    "plate 0 you see maximum argument at 0th\n",
    "38:13\n",
    "location and similarly we can bring this\n",
    "38:17\n",
    "the maximum prediction at at the first\n",
    "38:20\n",
    "location as well okay so at the first\n",
    "38:23\n",
    "location the maximum is you know the\n",
    "38:26\n",
    "argument - okay perfect so this is the\n",
    "38:30\n",
    "way how we work with the tensorflow 2.0\n",
    "38:33\n",
    "this is all about in this lesson please\n",
    "38:36\n",
    "don't forget to like this video and\n",
    "38:38\n",
    "subscribe this channel so that you can\n",
    "38:39\n",
    "get updates directly into your inbox in\n",
    "38:43\n",
    "further lessons all week also covering\n",
    "38:45\n",
    "more videos on a tensorflow and deep\n",
    "38:47\n",
    "learning till then bye bye and keep\n",
    "38:50\n",
    "learning\n",
    "\n",
    "\n",
    "'''\n",
    "def noTime(s):\n",
    "    l = s.split('\\n')\n",
    "    l2 = []\n",
    "    for i in l:\n",
    "      i = re.sub(r'\\d\\d:\\d\\d', \"\", i)\n",
    "      if len(i)!=0:\n",
    "        l2.append(i)\n",
    "    s2 = \"\\n\".join(l2)\n",
    "    return s2\n",
    "s2 = noTime(s)    \n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Introduction to the Machine Learning Projects](#Introduction-to-the-Machine-Learning-Projects)  \n",
      "[1 Rock Paper Scissors](#1-Rock-Paper-Scissors)  \n",
      "[2 Cat and Dog Image Classifier](#2-Cat-and-Dog-Image-Classifier)  \n",
      "[3 Book Recommendation Engine using KNN](#3-Book-Recommendation-Engine-using-KNN)  \n",
      "[4 Linear Regression Health Costs Calculator](#4-Linear-Regression-Health-Costs-Calculator)  \n",
      "[5 Neural Network SMS Text Classifier](#5-Neural-Network-SMS-Text-Classifier)  \n"
     ]
    }
   ],
   "source": [
    "s = '''\n",
    "Introduction to the Machine Learning Projects\n",
    "Not Passed\n",
    "Rock Paper Scissors\n",
    "Not Passed\n",
    "Cat and Dog Image Classifier\n",
    "Not Passed\n",
    "Book Recommendation Engine using KNN\n",
    "Not Passed\n",
    "Linear Regression Health Costs Calculator\n",
    "Not Passed\n",
    "Neural Network SMS Text Classifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "l = s.split('\\n')\n",
    "l2 = []\n",
    "for i in l:\n",
    "    if i.find(\"Passed\") == -1 \\\n",
    "    and i.strip() != \"\":\n",
    "        l2.append(i)\n",
    "l3 = []\n",
    "index = 0\n",
    "bigIndex = \"\"\n",
    "shead = \"\"\n",
    "words = [\"glich work\", \"glich view\"]\n",
    "for i in l2: \n",
    "   shead = bigIndex + str(index) + \". \" + i\n",
    "#    i = re.sub(r'Problem.*?: ', \"\", i) \n",
    "   if index != 0:\n",
    "        shead = str(index) + \" \" + i\n",
    "   else:\n",
    "        shead = i\n",
    "   shead = shead.replace(\"####\", \"\") \n",
    "   shead = shead.strip()\n",
    "   slink = shead.replace(\" \", \"-\")\n",
    "#    shead = words[index-1]\n",
    "   shead = \"[\" + shead + \"]\" \n",
    "   slink = \"(#\" + slink + \")  \" \n",
    "   l3.append(shead + slink)\n",
    "   index += 1\n",
    "s2 = \"\\n\".join(l3)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Introduction to the Machine Learning Projects\n",
      "```\n",
      "```\n",
      "#### 1 Rock Paper Scissors\n",
      "```\n",
      "```\n",
      "#### 2 Cat and Dog Image Classifier\n",
      "```\n",
      "```\n",
      "#### 3 Book Recommendation Engine using KNN\n",
      "```\n",
      "```\n",
      "#### 4 Linear Regression Health Costs Calculator\n",
      "```\n",
      "```\n",
      "#### 5 Neural Network SMS Text Classifier\n",
      "```\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# s = '''\n",
    "# '''\n",
    "l = s.split('\\n')\n",
    "l2 = []\n",
    "for i in l:\n",
    "    if i.find(\"Passed\") == -1 \\\n",
    "    and i.strip() != \"\":\n",
    "        l2.append(i)\n",
    "l3 = []\n",
    "index = 0\n",
    "for i in l2: \n",
    "   i = re.sub(r'Problem.*?: ', \"\", i) \n",
    "   if index != 0:\n",
    "        l3.append(\"#### \" + bigIndex + str(index) + \" \" + i)\n",
    "   else:\n",
    "        l3.append(\"#### \" + bigIndex + i)\n",
    "#    l3.append(\"#### \" + bigIndex +  i)\n",
    "   l3.append(\"```\")\n",
    "   l3.append(\"```\")\n",
    "   index += 1\n",
    "s2 = \"\\n\".join(l3)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = '''\n",
    "'''\n",
    "l = s.split('\\n')\n",
    "l2 = []\n",
    "for i in l:\n",
    "    if i.find(\"Passed\") == -1 \\\n",
    "    and i.strip() != \"\":\n",
    "        l2.append(i)\n",
    "l3 = []\n",
    "index = 1\n",
    "for i in l2: \n",
    "   l3.append(\"### \"+ \"3.\" + str(index) + \". \" + i)\n",
    "   index += 1\n",
    "s = \"\\n\".join(l3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google Переводчик](https://chrome.google.com/webstore/detail/google-translate/aapbdbdomjkkjkaonfhkkikfgjllcleb/related?hl=ru)  \n",
    "[4 расширения Chrome, которые мгновенно переводят выделенный текст](https://lifehacker.ru/chrome-translator/)  \n",
    "[]()  \n",
    "[]()  \n",
    "[]()  \n",
    "[]()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
